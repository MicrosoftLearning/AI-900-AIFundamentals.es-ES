{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Voz\r\n",
        "\r\n",
        "Cada vez será más habitual comunicarnos con sistemas de inteligencia artificial (IA) mediante nuestra voz y, a menudo, esperaremos una respuesta hablada.\r\n",
        "\r\n",
        "![Un robot hablando](./images/speech.jpg)\r\n",
        "\r\n",
        "*Reconocimiento de voz* (un sistema de IA que interpreta el lenguaje hablado) y *Síntesis de voz* (un sistema de IA que genera una respuesta hablada) son los componentes principales de una solución de IA habilitada por voz.\r\n",
        "\r\n",
        "## Crear un recurso de Cognitive Services\r\n",
        "\r\n",
        "Para crear un software que pueda interpretar el lenguaje hablado y responder de la misma manera, puede usar **Voz** de Cognitive Services, que permite convertir lenguaje hablado en texto y viceversa.\r\n",
        "\r\n",
        "Si no tiene uno, siga estos pasos para crear un recurso de **Cognitive Services** en su suscripción de Azure:\r\n",
        "\r\n",
        "> **Nota**: Si ya tiene un recurso de Cognitive Services, abra su página de **Inicio rápido** en Azure Portal y copie la clave y el punto de conexión en la siguiente celda. En caso contrario, siga estos pasos para crear uno.\r\n",
        "\r\n",
        "1. En la pestaña de otro explorador, abra Azure Portal (https://portal.azure.com) e inicie sesión con su cuenta de Microsoft.\r\n",
        "2. Haga clic en el botón **&#65291;Crear un recurso**, busque *Cognitive Services* y cree un recurso de **Cognitive Services** con esta configuración:\r\n",
        "    - **Suscripción**: *su suscripción de Azure*.\r\n",
        "    - **Grupo de recursos**: *seleccione o cree un grupo de recursos con un nombre único.*\r\n",
        "    - **Región**: *seleccione cualquier región disponible*:\r\n",
        "    - **Nombre**: *escriba un nombre único*.\r\n",
        "    - **Plan de tarifa**: S0\r\n",
        "    - **Confirmo que he leído y comprendido las notificaciones**: seleccionado.\r\n",
        "3. Espere a que la implementación finalice. Vaya al recurso de Cognitive Services y, en la página **Información general**, haga clic en el vínculo para administrar las claves del servicio. Necesitará la clave y la ubicación para conectarse a su recurso de Cognitive Services desde aplicaciones de cliente.\r\n",
        "\r\n",
        "### Obtener la clave y la ubicación de un recurso de Cognitive Services\r\n",
        "\r\n",
        "Para usar su recurso de Cognitive Services, las aplicaciones de cliente necesitan su clave de autenticación y su ubicación:\r\n",
        "\r\n",
        "1. En Azure Portal, en la página **Claves y punto de conexión** de su recurso de Cognitive Services, copie la **Key1** de su recurso y péguela en el siguiente código, en sustitución de **YOUR_COG_KEY**.\r\n",
        "2. Copie la **Ubicación** de su recurso y péguela en el siguiente código, en sustitución de **YOUR_COG_LOCATION**.\r\n",
        ">**Nota**: Quédese en la página **Claves y punto de conexión** y copie la **Ubicación** desde esta página, (ejemplo: _westus_). No_agregue_espacios entre las palabras del campo Ubicación. \r\n",
        "3. Ejecute el código siguiente. Para ello, haga clic en **Run cell** (&#9655;) a la izquierda de la celda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      },
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconocimiento de voz\r\n",
        "\r\n",
        "Digamos que quiere crear un sistema de automatización del hogar que acepte instrucciones habladas, como “turn the light on” para encender la luz y “turn the light off” para apagarla. Su aplicación debe ser capaz de reconocer el audio de su voz (su instrucción hablada), interpretarlo y convertirlo en texto para, después, procesarlo y analizarlo.\r\n",
        "\r\n",
        "Ya está listo para transcribir audio. La entrada de audio puede recibirse a través de un **micrófono** o mediante un **archivo de audio**. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reconocimiento de voz con un archivo de audio\r\n",
        "\r\n",
        "Ejecute la celda siguiente para ver cómo funciona el servicio Reconocimiento de voz con un **archivo de audio**. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Get spoken command from audio file\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Configure speech recognizer\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Use a one-time, synchronous call to transcribe the speech\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Play the original audio file\r\n",
        "playsound(audio_file)\n",
        "\n",
        "# Show transcribed text from audio file\r\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Síntesis de voz\r\n",
        "\r\n",
        "Ya hemos visto cómo usar el servicio Voz para transcribir el lenguaje hablado, pero ¿qué pasa si queremos convertir el texto en voz? ¿Cómo podemos hacerlo?\r\n",
        "\r\n",
        "Supongamos que su sistema de automatización del hogar ha interpretado un comando para encender la luz (“turn the light on”). Lo esperado sería que el sistema respondiera al comando y que, además, realizase la acción solicitada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Get text to be spoken\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Configure speech synthesis\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Transcribe text into speech\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Display an appropriate image\r\n",
        "file_name = response_text.lower() + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cambie la variable **response_text** a *Turning the light off.* (incluido el punto final) y vuelva a ejecutar la celda para escuchar el resultado.\r\n",
        "\r\n",
        "## Más información\r\n",
        "\r\n",
        "En este cuaderno, hemos visto un sencillo ejemplo sobre cómo usar el servicio Voz, de Cognitive Services. Puede obtener más información sobre [Conversión de voz en texto](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) y [Conversión de texto en voz](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) en la documentación del servicio Voz."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}